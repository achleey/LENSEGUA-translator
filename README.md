# Traductor LENSEGUA
<img src="https://raw.githubusercontent.com/achleey/TraductorLENSEGUA/main/src/LENSEGUA.jpeg" width="500" height = 300>

This project aims to develop a comprehensive desktop application for translating Guatemalan Sign Language (LENSEGUA) using computer vision and machine learning. The initial version sets up the framework for real-time video processing and sign language recognition, utilizing computer vision techniques to capture and interpret signs. The application integrates machine learning models to translate detected signs into text and audio, providing an interactive and efficient translation tool. The ultimate goal is to create a robust system for translating Guatemalan Sign Language in real-time, facilitating communication and accessibility.

Table of Contents

- [Features](#features)
- [System Requirements](#system-requirements)
- [Repository Structure](#repository-structure)
- [Dependencies](#dependencies)
